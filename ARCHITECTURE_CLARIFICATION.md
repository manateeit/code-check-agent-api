# API Architecture - Dual AI System

## âœ… Correct Implementation - Two-Phase Approach

Your API **DOES** use both Perplexity and OpenAI/Gemini, each for their specialized task.

### ğŸ¯ The Two-Phase Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Request                                                 â”‚
â”‚  POST /research                                              â”‚
â”‚  { "address": "...", "llm_provider": "openai" }             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CodeCheckAgent.__init__()                                   â”‚
â”‚                                                              â”‚
â”‚  self.perplexity = PerplexityClient()     â—„â”€â”€ ALWAYS used  â”‚
â”‚  self.llm = LLMClient("openai")           â—„â”€â”€ User's choice â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  For Each Section (Ã—13)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: Research (Perplexity - ALWAYS)                    â”‚
â”‚                                                              â”‚
â”‚  result = self.perplexity.search(query)                     â”‚
â”‚    â†“                                                         â”‚
â”‚  Returns:                                                    â”‚
â”‚    - Raw text from web search                               â”‚
â”‚    - Citation URLs                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: Extraction (OpenAI/Gemini - User Choice)          â”‚
â”‚                                                              â”‚
â”‚  return self.llm.extract_data(                              â”‚
â”‚      content=perplexity_result,                             â”‚
â”‚      schema=WallSigns,                                      â”‚
â”‚      instructions="Extract..."                              â”‚
â”‚  )                                                           â”‚
â”‚    â†“                                                         â”‚
â”‚  Returns:                                                    â”‚
â”‚    - Structured Pydantic model                              â”‚
â”‚    - Fields mapped to source URLs                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Code Evidence

### Agent Initialization (app/agent.py:24-26)

```python
def __init__(self, llm_provider: str = "openai"):
    self.perplexity = PerplexityClient()      # â† ALWAYS initialized
    self.llm = LLMClient(provider=llm_provider)  # â† User chooses this
```

### Research Flow (app/agent.py:42, 52)

```python
# Phase 1: Perplexity searches
result = self.perplexity.search(query)  # â† Line 42

# Phase 2: LLM extracts
return self.llm.extract_data(full_content, LocationInformation, ...)  # â† Line 52
```

## ğŸ”‘ What `llm_provider` Parameter Controls

**It does NOT mean "only use this LLM"**

It means: **"Which LLM should extract data from Perplexity's research?"**

### Request Example:

```json
{
  "address": "401 Biscayne Blvd, Miami, FL",
  "llm_provider": "openai"
}
```

**What happens:**

1. âœ… **Perplexity** searches the web (13 queries)
2. âœ… **OpenAI** extracts structured data from Perplexity's results (13 extractions)

### Alternative Request:

```json
{
  "address": "401 Biscayne Blvd, Miami, FL",
  "llm_provider": "gemini"
}
```

**What happens:**

1. âœ… **Perplexity** searches the web (13 queries) â† Same as above
2. âœ… **Gemini** extracts structured data from Perplexity's results (13 extractions) â† Different extractor

## ğŸ’° Cost Breakdown Per Request

### With OpenAI:
- **Perplexity** (research): 13 queries Ã— $0.05 = **$0.65**
- **OpenAI** (extraction): 13 extractions Ã— $0.02 = **$0.26**
- **Total:** **$0.91**

### With Gemini:
- **Perplexity** (research): 13 queries Ã— $0.05 = **$0.65**
- **Gemini** (extraction): 13 extractions Ã— $0.005 = **$0.07**
- **Total:** **$0.72** (20% cheaper)

## ğŸ¯ Why This Architecture?

### Perplexity's Strengths:
âœ… Real-time web search with citations
âœ… Finds current, official government sources
âœ… Returns raw text + source URLs

### OpenAI/Gemini's Strengths:
âœ… Excellent at structured data extraction
âœ… Maps fields to source citations
âœ… Handles complex nested models (Pydantic)

## ğŸ” Verification

You can trace this in the logs when the API runs:

```
[Research Phase - Perplexity]
Searching: "What are the wall sign regulations for 401 Biscayne Blvd..."
â† Returns raw text + citations

[Extraction Phase - OpenAI/Gemini]
Extracting structured data using gpt-4o...
â† Returns WallSigns Pydantic model
```

## âœ… Summary

**Your API correctly implements the dual-AI architecture:**

1. ğŸ” **Perplexity** = Research & Search (always used)
2. ğŸ§  **OpenAI/Gemini** = Data Extraction (user's choice)

The `llm_provider` parameter lets users choose which extraction engine to use, **NOT** which research engine (Perplexity is always used for research).

This matches your original prototype design exactly! âœ¨
